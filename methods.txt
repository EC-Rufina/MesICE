In this file you will find all the details on how the programs were run

##FastANI
#belowe there is a small script to run FastANI between a set of genomes in .fasta located in the folder input_genomes/

$ runFastANI_loop.sh
#!/bin/bash
##add all your genome sequences in fasta format into the folder input_genomes/ and then run me

#create a text file for the FastANI command
for filename in input_genomes/*.fasta; do
	echo "$filename" >> path_coregenomes.txt	
done

#now you run FastANI
fastANI --ql path_coregenomes.txt --rl path_coregenomes.txt --matrix -o FastANIscores


##hmmscan in a loop
#MOB profiles were dowloaded from https://github.com/gem-pasteur/Macsyfinder_models/tree/master/models/Conjugation/profiles
#same command was run to search coupling proteins

#MOB profiles were combined and the database built using hppress
#our database MOB.hmm was added to the folder MOB_search/database/
#then the search was run as follow

for filename in prokka_annotation/*.faa; do genomefaaname=${filename/prokka_annotation\/}; genome=${genomefaaname%.*}; hmmscan --cpu 16 -T 30 --tblout MOB_search/"$genome"_MOB.txt -o MOB_search/"$genome"_MOBresults.txt /MOB_search/database/MOB.hmm "$filename"; done

##backbone identification
#all ICE were reannotated with prokka, all prokka outputs were placed in the folder UniqueICEs_Prokka
#proteinortho was run as 
proteinortho -clean -singles  /UniqueICEs_Prokka/*.faa -project=UniqueICEs_prortho
#roary was run as
roary -f ./ICEscore_40 -e -n -v -i 40 -s ./UniqueICEs_Prokka/*.gff

##ClonalFrameML
#we used this command to see if there was recombination between the backbone genes of the ICEs
#the concatenation of the alignment of the backbone genes file is named BBalignment.fasta
#the PhyML tree used as input was the one used for figure 2A and it is called ICEtree.newick

ClonalFrameML ClFr/input/ICEtree.newick ClFr/input/BBalignment.fasta ClFr/output/UniqueICEs_bb


##Alfy
#Before running alfy the dataset folder was created where each file was a multifasta file.
#each input sequence had a corresponding multifasta file named as the input sequence file and contained the sequence of all the Unique ICEs with the exception of input sequence (which is also the name of the dataset file)
#then an Alfy loop was run as follow 

for file in UniqueICEs_input/*.fasta; do filename=${file//UniqueICEs_input\/}; ./alfy -i UniqueICEs_input/"$filename" -j ICEalfy/dataset/"$filename" -w 1000 -M -P 0.05 | awk -f Scripts/quantifyGenotypes.awk >> ICEalfy/results/All_Unique_w1000.txt; echo -e "\n" >> ICEalfy/results/All_Unique_w1000.txt; done

#Alfy output would look like this for each ICEquery
>ICEquery
ICEA	12
ICEB	9
ICEC	1
...

To make it readable for cytoscape you need to trasform it as:
ICEquery	ICEA	12
ICEquery	ICEB	9
ICEquery	ICEC	1

if the ICEquery has no homologies to anyother element leave it blank
ICEquery		

combine all the outputs for the queries and use it as input for cytoscape


##association analysis
#association analysis was performed using scoary which reads the output of roary.
#first roary was run on the Symbiosis ICE (excluding tRNA-His integrated ICE), then scory was run on Roary's output
roary -f ./ICEscore_70 -e -n -v -i 70 -s ./UniqueICEs_Prokka_noHis/*.gff
scoary -g ICEscore_70/gene_presence_absence.csv -t ICEscore_70/traits.csv
