In this file you will find all the details on how the programs were run

##FastANI
#below there is a small script to run FastANI between a set of genomes in .fasta format located in the folder input_genomes/

$ runFastANI_loop.sh
#!/bin/bash
##add all your genome sequences in fasta format into the folder input_genomes/ and then run me

#create a text file for the FastANI command
for filename in input_genomes/*.fasta; do
	echo "$filename" >> path_coregenomes.txt	
done

#now you run FastANI
fastANI --ql path_coregenomes.txt --rl path_coregenomes.txt --matrix -o FastANIscores


##hmmscan in a loop
#MOB profiles were downloaded from https://github.com/gem-pasteur/Macsyfinder_models/tree/master/models/Conjugation/profiles
#same command was run to search coupling proteins

#MOB profiles were combined and the database built using hmmpress
#our database MOB.hmm was added to the folder MOB_search/database/
#then the search was run as follow

for filename in prokka_annotation/*.faa; do genomefaaname=${filename/prokka_annotation\/}; genome=${genomefaaname%.*}; hmmscan --cpu 16 -T 30 --tblout MOB_search/"$genome"_MOB.txt -o MOB_search/"$genome"_MOBresults.txt /MOB_search/database/MOB.hmm "$filename"; done

##backbone identification
#all ICEs were reannotated with prokka, all prokka outputs were placed in the folder UniqueICEs_Prokka
#proteinortho was run as 
proteinortho -clean -singles /UniqueICEs_Prokka/*.faa -project=UniqueICEs_prortho
#roary was run as
roary -f ./ICEscore_40 -e -n -v -i 40 -s ./UniqueICEs_Prokka/*.gff

##ClonalFrameML
#we used this command to see if there was recombination between the backbone genes of the ICEs
#the concatenation of the alignment of the backbone genes file is named BBalignment.fasta
#the PhyML tree used as input was the one used for figure 2A and it is called ICEtree.newick

ClonalFrameML ClFr/input/ICEtree.newick ClFr/input/BBalignment.fasta ClFr/output/UniqueICEs_bb


##Alfy
#Before running alfy the 'dataset' folder was created where each file was a multifasta file.
#each input sequence had a corresponding multifasta file in the 'dataset' folder named as the input sequence file and it contained the sequence of all the Unique ICEs with the exception of input sequence (which is also the name of the dataset file)
#then an Alfy loop was run as follow 

for file in UniqueICEs_input/*.fasta; do filename=${file//UniqueICEs_input\/}; ./alfy -i UniqueICEs_input/"$filename" -j /dataset/"$filename" -w 1000 -M -P 0.05 | awk -f Scripts/quantifyGenotypes.awk >> Alfy_results/All_Unique_w1000.txt; echo -e "\n" >> Alfy_results_results/All_Unique_w1000.txt; done

#Alfy output would look like this for each ICEquery
>ICEquery
ICEA	12
ICEB	9
ICEC	1
...

To make it readable for cytoscape you need to trasform it as:
ICEquery	ICEA	12
ICEquery	ICEB	9
ICEquery	ICEC	1

if the ICEquery has no homologies, leave it blank
ICEquery		

combine the outputs for all the queries and use it as input for cytoscape (include headers)


##association analysis
#association analysis was performed using scoary which reads the output of roary.
#Roary was run on all ICEs then only on the ICESyms (excluding tRNA-His integrated ICE), then scory was run on Roary's output
#you need to make a traits.csv file where each line is your ICE named as in the input for Roary and in each column (one column one trait) you add a 0 or 1 if your element has a trait (1) or not (0).
#to isolate genes involved in symbiosis 
roary -f ./ICEscore_40 -e -n -v -i 40 -s ./UniqueICEs_Prokka/*.gff  #which is the same command of the backbone identification
scoary -g ICEscore_40/gene_presence_absence.csv -t ICEscore_40/traits.csv

#to isolate plant-associated genes 
roary -f ./ICEscore_70 -e -n -v -i 70 -s ./UniqueICEs_Prokka_noHis/*.gff
scoary -g ICEscore_70/gene_presence_absence.csv -t ICEscore_70/traits.csv


##For the trees in Figure S5 and S6, genes were aligned with the mafft algorithm and the tree built by calling
raxmlHPC -f a -p $RANDOM -x $RANDOM -N 100 -m GTRCATX -T 16 -s input_aln.fasta -n mytree 

